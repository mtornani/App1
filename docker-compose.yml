version: '3.8'

services:
  frontend:
    build:
      context: ./frontend
      dockerfile: Dockerfile
    ports:
      - "3000:3000"
    depends_on:
      - backend-node
    environment:
      - NEXT_PUBLIC_BACKEND_URL=http://localhost:3001

  backend-node:
    build:
      context: ./backend-node
      dockerfile: Dockerfile
    ports:
      - "3001:3001"
    environment:
      - DATABASE_URL=sqlite:///app/data/database.sqlite
      - EMBEDDING_SERVICE_URL=http://embedding-service:8000
      # - OPENROUTER_API_KEY=${OPENROUTER_API_KEY}
      # - SERPAPI_KEY=${SERPAPI_KEY}
      - LOCAL_LLM_ENABLED=false
    volumes:
      # Volume esplicito per i dati del backend
      - type: bind
        source: ./backend-node/data
        target: /app/data
    depends_on:
      - db-setup
      - embedding-service

  embedding-service:
    build:
      context: ./backend-python
      dockerfile: Dockerfile
    ports:
      - "8000:8000"
    environment:
      - PORT=8000
      # Passa il token Hugging Face come variabile d'ambiente (se necessario)
      - HUGGING_FACE_HUB_TOKEN=${HUGGING_FACE_HUB_TOKEN}
    volumes:
      # Monta la directory locale del modello nella posizione prevista dal servizio Python
      - type: bind
        source: ./models/embeddinggemma-300m-local
        target: /app/local-model

  db-setup:
    image: node:18-alpine
    volumes:
      # Volume esplicito per inizializzare la directory data
      - type: bind
        source: ./backend-node/data
        target: /app/data
    working_dir: /app
    command: sh -c "mkdir -p data && chmod 777 data"
    restart: "no"
